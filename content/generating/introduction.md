### Introduction
{:#generating_introduction}

The [Resource Description Framework (RDF)](cite:cites spec:rdf) and [Linked Data](cite:cites linkeddata) technologies enable distributed use and management of semantic data models.
Datasets with an interoperable domain model can be stored and queried by different data owners in different ways.
In order to discover the strengths and weaknesses of different storage and querying possibilities,
data-driven benchmarks with different sizes of datasets and varying characteristics can be used.

Regardless of whether existing data-driven benchmarks use real or synthetic datasets,
the *external validity* of their results can be too limited,
which makes a&nbsp;generalization to other datasets difficult.
Real datasets, on the one hand, are often only scarcely available for testing,
and only cover very specific scenarios,
such that not all aspects of systems can be assessed.
Synthetic datasets, on the other hand, are typically generated by
[*mimicking algorithms*](cite:cites berlinsparqlbenchmark,lubmbenchmark,sp2benchmark,socialnetworkdatasetgenerator),
which are [not always sufficiently realistic](cite:cites rdfbenchmarksdatasets).
Features that are relevant for real-world datasets may not be tested.
As such, conclusions drawn from existing benchmarks
do not always apply to the envisioned real-world scenarios.
One way to get the best of both worlds
is to design mimicking algorithms that generate realistic synthetic datasets.

The *public transport* domain provides data with both geospatial and temporal properties,
which makes this an especially interesting source of data for benchmarking.
Its representation as Linked Data is valuable because
1) of the many shared entities, such as stops, routes and trips, across different existing datasets on the Web,
2) these entities can be distributed over different datasets
and 3) benefit from interlinking for the improvement of discoverability.
Synthetic public transport datasets are particularly important and needed
in cases where public transport route planning algorithms are evaluated.
The [Linked Connections framework](cite:cites linkedconnections) and [Connection Scan Algorithm](cite:cites csa)
are examples of such public transport route planning systems.
Because of the limited availability of real-world datasets with desired properties,
these systems were evaluated with only a very low number of datasets, respectively one and three datasets.
A synthetic public transport dataset generator would make it easier for researchers
to include a higher number of realistic datasets with various properties in their evaluations,
which would be beneficial to the discovery of new insights from the evaluations.
Network size, network sparsity and temporal range are examples of such properties,
and different combinations of them may not always be available in real datasets,
which motivates the need for generating synthetic, but realistic datasets with these properties.

Not only are public transport datasets useful for benchmarking route planning systems,
they are also highly useful for benchmarking [geospatial](cite:cites strabon,parliament) and [temporal](cite:cites csparql,cqels) RDF systems
due to the intrinsic geospatial and temporal properties of public transport datasets.
While synthetic dataset generators already exist in the [geospatial and temporal domain](cite:cites geographicabenchmark,lsbench),
no systems exist yet that focus on realism, and specifically look into the generation of public transport datasets.
As such, the main topic that we address in this work, is solving the need for realistic public transport datasets
with geospatial and temporal characteristics,
so that they can be used to benchmark RDF data management and route planning systems.
More specifically, we introduce a mimicking algorithm for generating realistic public transport data,
which is the main contribution of this work.

We observed a significant correlation between transport networks and the population distributions of their geographical areas,
which is why population distributions are the driving factor within our algorithm.
The cause of this correlation is obvious, considering transport networks are frequently used to transport people,
but other -- possibly independent -- factors exist that influence transport networks as well,
like certain points of interest such as tourist attractions and shopping areas.
Our algorithm is subdivided into five sequential steps,
inspired by existing methodologies from the domains of [public transit planning](cite:cites transitnetworkdesignscheduling)
as a means to improve the realism of the algorithm's output data.
These steps include the creation of a geospatial region, the placement of stops, edges and routes, and the scheduling of trips.
We provide an implementation of this algorithm, with different parameters to configure the algorithm.
Finally, we confirm the realism of datasets that are generated by this algorithm
using the existing [generic structuredness measure](cite:cites rdfbenchmarksdatasets)
and new measures that we introduce, which are specific to the public transport domain.
The notable difference of this work compared to other synthetic dataset generators
is that our generation algorithm specializes in generating public transit networks,
while other generators either focus on other domains, or aim to be more general-purpose.
Furthermore, our algorithm is based on population distributions and existing methodologies from public transit network design.

In the next section, we introduce the related work on dataset generation,
followed by the background on public transit network design, and transit feed formats in [](#generating_public-transit-background).
In [](#generating_research-question), we introduce the main research question and hypothesis of this work.
Next, our algorithm is presented in [](#generating_methodology), followed by its implementation in [](#generating_implementation).
In [](#generating_evaluation), we present the evaluation of our implementation,
followed by a discussion and conclusion in [](#generating_discussion) and [](#generating_conclusions).